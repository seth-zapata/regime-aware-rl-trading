{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Milestone 1: Data Pipeline Exploration\n",
    "\n",
    "This notebook provides interactive exploration of the multi-source data pipeline:\n",
    "- **PriceLoader**: Yahoo Finance OHLCV + technical features\n",
    "- **FREDLoader**: Macroeconomic indicators from FRED\n",
    "- **EDGARLoader**: SEC filings (10-K, 10-Q)\n",
    "- **DataPipeline**: Unified data alignment\n",
    "\n",
    "Run each cell to explore the data and verify everything works correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src to path\n",
    "sys.path.insert(0, str(Path.cwd().parent / 'src'))\n",
    "\n",
    "# Load environment variables\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(Path.cwd().parent / '.env')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Configure display\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.width', 200)\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Price Data (Yahoo Finance)\n",
    "\n",
    "Load OHLCV data and explore technical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.price_loader import PriceLoader\n",
    "\n",
    "price_loader = PriceLoader()\n",
    "\n",
    "# Fetch SPY data\n",
    "price_df = price_loader.get_price_data(\n",
    "    symbol='SPY',\n",
    "    start_date='2020-01-01',\n",
    "    end_date='2024-01-01'\n",
    ")\n",
    "\n",
    "print(f\"Shape: {price_df.shape}\")\n",
    "print(f\"Date range: {price_df.index.min()} to {price_df.index.max()}\")\n",
    "print(f\"\\nColumns: {list(price_df.columns)}\")\n",
    "price_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add technical features\n",
    "price_features = price_loader.add_technical_features(price_df)\n",
    "\n",
    "print(f\"Total features: {len(price_features.columns)}\")\n",
    "print(f\"\\nNew columns added:\")\n",
    "new_cols = [c for c in price_features.columns if c not in price_df.columns]\n",
    "for col in new_cols:\n",
    "    print(f\"  - {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize price and some indicators\n",
    "fig, axes = plt.subplots(3, 1, figsize=(14, 10), sharex=True)\n",
    "\n",
    "# Price with SMAs\n",
    "ax1 = axes[0]\n",
    "ax1.plot(price_features.index, price_features['Close'], label='Close', alpha=0.8)\n",
    "ax1.plot(price_features.index, price_features['sma_50'], label='SMA 50', alpha=0.7)\n",
    "ax1.plot(price_features.index, price_features['sma_200'], label='SMA 200', alpha=0.7)\n",
    "ax1.set_ylabel('Price ($)')\n",
    "ax1.legend()\n",
    "ax1.set_title('SPY Price with Moving Averages')\n",
    "\n",
    "# RSI\n",
    "ax2 = axes[1]\n",
    "ax2.plot(price_features.index, price_features['rsi_14'], color='purple')\n",
    "ax2.axhline(70, color='red', linestyle='--', alpha=0.5, label='Overbought')\n",
    "ax2.axhline(30, color='green', linestyle='--', alpha=0.5, label='Oversold')\n",
    "ax2.set_ylabel('RSI')\n",
    "ax2.set_ylim(0, 100)\n",
    "ax2.legend()\n",
    "ax2.set_title('RSI (14-day)')\n",
    "\n",
    "# Volatility\n",
    "ax3 = axes[2]\n",
    "ax3.plot(price_features.index, price_features['volatility_21d'] * 100, label='21-day Vol', color='orange')\n",
    "ax3.set_ylabel('Volatility (%)')\n",
    "ax3.set_xlabel('Date')\n",
    "ax3.legend()\n",
    "ax3.set_title('Annualized Volatility')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Macro Data (FRED)\n",
    "\n",
    "Load macroeconomic indicators used for regime detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.fred_loader import FREDLoader, FRED_SERIES, DEFAULT_REGIME_SERIES\n",
    "\n",
    "# Show available series\n",
    "print(\"Available FRED Series:\")\n",
    "for series_id, description in FRED_SERIES.items():\n",
    "    marker = \"*\" if series_id in DEFAULT_REGIME_SERIES else \" \"\n",
    "    print(f\"  {marker} {series_id}: {description}\")\n",
    "\n",
    "print(f\"\\n* = Default regime detection series\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fred_loader = FREDLoader()\n",
    "\n",
    "# Fetch macro indicators\n",
    "macro_df = fred_loader.get_macro_indicators(\n",
    "    series=DEFAULT_REGIME_SERIES,\n",
    "    start_date='2020-01-01',\n",
    "    end_date='2024-01-01'\n",
    ")\n",
    "\n",
    "print(f\"Shape: {macro_df.shape}\")\n",
    "print(f\"Date range: {macro_df.index.min()} to {macro_df.index.max()}\")\n",
    "macro_df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize key macro indicators\n",
    "fig, axes = plt.subplots(3, 2, figsize=(14, 10))\n",
    "\n",
    "# Yield Curve (10Y-2Y spread)\n",
    "ax = axes[0, 0]\n",
    "ax.plot(macro_df.index, macro_df['T10Y2Y'], color='blue')\n",
    "ax.axhline(0, color='red', linestyle='--', alpha=0.7, label='Inversion threshold')\n",
    "ax.fill_between(macro_df.index, macro_df['T10Y2Y'], 0, \n",
    "                where=macro_df['T10Y2Y'] < 0, color='red', alpha=0.3, label='Inverted')\n",
    "ax.set_ylabel('Spread (%)')\n",
    "ax.set_title('Yield Curve (10Y - 2Y Treasury)')\n",
    "ax.legend()\n",
    "\n",
    "# VIX\n",
    "ax = axes[0, 1]\n",
    "ax.plot(macro_df.index, macro_df['VIXCLS'], color='purple')\n",
    "ax.axhline(20, color='green', linestyle='--', alpha=0.5, label='Low vol')\n",
    "ax.axhline(30, color='orange', linestyle='--', alpha=0.5, label='Elevated')\n",
    "ax.set_ylabel('VIX')\n",
    "ax.set_title('VIX Volatility Index')\n",
    "ax.legend()\n",
    "\n",
    "# Unemployment\n",
    "ax = axes[1, 0]\n",
    "ax.plot(macro_df.index, macro_df['UNRATE'], color='brown')\n",
    "ax.set_ylabel('Rate (%)')\n",
    "ax.set_title('Unemployment Rate')\n",
    "\n",
    "# Fed Funds Rate\n",
    "ax = axes[1, 1]\n",
    "ax.plot(macro_df.index, macro_df['FEDFUNDS'], color='green')\n",
    "ax.set_ylabel('Rate (%)')\n",
    "ax.set_title('Federal Funds Rate')\n",
    "\n",
    "# Credit Spread\n",
    "ax = axes[2, 0]\n",
    "ax.plot(macro_df.index, macro_df['BAA10Y'], color='red')\n",
    "ax.axhline(2, color='gray', linestyle='--', alpha=0.5)\n",
    "ax.set_ylabel('Spread (%)')\n",
    "ax.set_title('BAA Corporate Bond Spread')\n",
    "ax.set_xlabel('Date')\n",
    "\n",
    "# Correlation heatmap\n",
    "ax = axes[2, 1]\n",
    "corr = macro_df.corr()\n",
    "sns.heatmap(corr, annot=True, cmap='RdBu_r', center=0, ax=ax, fmt='.2f')\n",
    "ax.set_title('Correlation Matrix')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add derived features\n",
    "macro_features = fred_loader.calculate_derived_features(macro_df)\n",
    "\n",
    "print(\"Derived features added:\")\n",
    "new_cols = [c for c in macro_features.columns if c not in macro_df.columns]\n",
    "for col in new_cols:\n",
    "    print(f\"  - {col}\")\n",
    "\n",
    "# Show yield curve inversion periods\n",
    "inverted_periods = macro_features[macro_features['T10Y2Y_inverted'] == 1]\n",
    "print(f\"\\nYield curve inverted on {len(inverted_periods)} days\")\n",
    "print(f\"Inversion periods: {inverted_periods.index.min()} to {inverted_periods.index.max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. SEC Filings (EDGAR)\n",
    "\n",
    "Explore SEC filing data for a sample company."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.edgar_loader import EDGARLoader\n",
    "\n",
    "edgar_loader = EDGARLoader(email=\"research@example.com\")\n",
    "\n",
    "# Get CIK for Apple\n",
    "cik = edgar_loader.get_cik('AAPL')\n",
    "print(f\"Apple CIK: {cik}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch recent 10-K filings\n",
    "filings = edgar_loader.get_filings(\n",
    "    ticker='AAPL',\n",
    "    filing_type='10-K',\n",
    "    count=5\n",
    ")\n",
    "\n",
    "print(f\"Found {len(filings)} 10-K filings:\\n\")\n",
    "for f in filings:\n",
    "    print(f\"  {f.filing_date}: {f.filing_type}\")\n",
    "    print(f\"    Company: {f.company_name}\")\n",
    "    print(f\"    URL: {f.document_url[:80]}...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get filings as DataFrame (without extracting text for speed)\n",
    "filings_df = edgar_loader.get_filings_dataframe(\n",
    "    'AAPL',\n",
    "    filing_types=['10-K', '10-Q'],\n",
    "    start_date='2020-01-01',\n",
    "    extract_text=False\n",
    ")\n",
    "\n",
    "print(f\"Total filings: {len(filings_df)}\")\n",
    "print(f\"\\nFiling type distribution:\")\n",
    "print(filings_df['filing_type'].value_counts())\n",
    "\n",
    "filings_df[['filing_date', 'filing_type', 'company_name']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Extract text from most recent filing (takes a few seconds)\n",
    "# Uncomment to run\n",
    "\n",
    "# if filings:\n",
    "#     print(f\"Extracting text from {filings[0].filing_date} 10-K...\")\n",
    "#     text_sections = edgar_loader.extract_filing_text(filings[0])\n",
    "#     \n",
    "#     for section, text in text_sections.items():\n",
    "#         print(f\"\\n{section}: {len(text):,} characters\")\n",
    "#         print(f\"Preview: {text[:500]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Unified Data Pipeline\n",
    "\n",
    "Load and align data from all sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.data_pipeline import DataPipeline\n",
    "\n",
    "pipeline = DataPipeline()\n",
    "\n",
    "# Load aligned data (price + macro)\n",
    "aligned_df = pipeline.load_aligned_data(\n",
    "    symbol='SPY',\n",
    "    start_date='2020-01-01',\n",
    "    end_date='2024-01-01',\n",
    "    include_price=True,\n",
    "    include_macro=True,\n",
    "    include_filings=False  # Skip for speed\n",
    ")\n",
    "\n",
    "print(f\"Aligned data shape: {aligned_df.shape}\")\n",
    "print(f\"Date range: {aligned_df.index.min()} to {aligned_df.index.max()}\")\n",
    "\n",
    "# Group columns by source\n",
    "price_cols = [c for c in aligned_df.columns if c.startswith('price_')]\n",
    "macro_cols = [c for c in aligned_df.columns if c.startswith('macro_')]\n",
    "\n",
    "print(f\"\\nPrice features: {len(price_cols)}\")\n",
    "print(f\"Macro features: {len(macro_cols)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "missing = aligned_df.isna().sum()\n",
    "missing_pct = (missing / len(aligned_df) * 100).round(2)\n",
    "\n",
    "print(\"Missing values (>0%):\")\n",
    "print(missing_pct[missing_pct > 0].sort_values(ascending=False).head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create modeling dataset\n",
    "X, y = pipeline.create_modeling_dataset(\n",
    "    symbol='SPY',\n",
    "    start_date='2020-01-01',\n",
    "    end_date='2024-01-01',\n",
    "    target_horizon=1,\n",
    "    target_type='direction'\n",
    ")\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"\\nTarget distribution:\")\n",
    "print(y.value_counts(normalize=True).round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train/val/test split\n",
    "splits = pipeline.get_train_test_split(X, y, test_ratio=0.2, val_ratio=0.1)\n",
    "\n",
    "print(\"Data Splits (Time-Based):\")\n",
    "print(\"=\" * 50)\n",
    "for name, (X_split, y_split) in splits.items():\n",
    "    print(f\"\\n{name.upper()}:\")\n",
    "    print(f\"  Samples: {len(X_split):,}\")\n",
    "    print(f\"  Date range: {X_split.index.min().date()} to {X_split.index.max().date()}\")\n",
    "    print(f\"  Target balance: {y_split.mean():.2%} positive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize train/val/test split\n",
    "fig, ax = plt.subplots(figsize=(14, 4))\n",
    "\n",
    "colors = {'train': 'blue', 'val': 'orange', 'test': 'green'}\n",
    "for name, (X_split, y_split) in splits.items():\n",
    "    ax.axvspan(X_split.index.min(), X_split.index.max(), \n",
    "               alpha=0.3, color=colors[name], label=f\"{name} ({len(X_split)} samples)\")\n",
    "\n",
    "# Overlay price\n",
    "ax2 = ax.twinx()\n",
    "ax2.plot(aligned_df.index, aligned_df['price_Close'], color='black', alpha=0.5, linewidth=0.5)\n",
    "ax2.set_ylabel('SPY Price')\n",
    "\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_title('Time-Based Train/Validation/Test Split')\n",
    "ax.legend(loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Feature Analysis\n",
    "\n",
    "Explore feature distributions and correlations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature statistics\n",
    "X_train, y_train = splits['train']\n",
    "\n",
    "print(\"Feature Statistics (Training Set):\")\n",
    "X_train.describe().T.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation with target (on training set only)\n",
    "correlations = X_train.corrwith(y_train).sort_values(key=abs, ascending=False)\n",
    "\n",
    "print(\"Top 15 features correlated with target:\")\n",
    "print(correlations.head(15).round(4))\n",
    "\n",
    "print(\"\\nBottom 15 features (least correlated):\")\n",
    "print(correlations.tail(15).round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize top correlations\n",
    "top_features = correlations.head(10).index.tolist()\n",
    "\n",
    "fig, axes = plt.subplots(2, 5, figsize=(16, 6))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, feature in enumerate(top_features):\n",
    "    ax = axes[i]\n",
    "    \n",
    "    # Box plot by target class\n",
    "    for label in [0, 1]:\n",
    "        data = X_train.loc[y_train == label, feature].dropna()\n",
    "        color = 'red' if label == 0 else 'green'\n",
    "        ax.hist(data, bins=30, alpha=0.5, color=color, label=f\"{'Down' if label == 0 else 'Up'}\")\n",
    "    \n",
    "    ax.set_title(f\"{feature}\\n(corr={correlations[feature]:.3f})\")\n",
    "    ax.legend(fontsize=8)\n",
    "\n",
    "plt.suptitle('Feature Distributions by Target Class (Training Set)', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "The data pipeline is working correctly:\n",
    "\n",
    "1. **PriceLoader**: Successfully fetches OHLCV and computes 20+ technical features\n",
    "2. **FREDLoader**: Fetches 5 key macro indicators with derived features\n",
    "3. **EDGARLoader**: Can fetch and parse SEC filings\n",
    "4. **DataPipeline**: Aligns all sources to daily frequency with proper time-based splits\n",
    "\n",
    "**Next Steps**: Milestone 2 - Regime Detection using the macro indicators."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
